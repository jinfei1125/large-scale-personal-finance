{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5TRANSFORMER-blackhumorQ&A.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/T5TRANSFORMER.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Text Summarization & Question Answering using google's T5 Transformer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1sZkQkt3sXX"
      },
      "source": [
        "### Spark NLP documentation and instructions:\n",
        "https://nlp.johnsnowlabs.com/docs/en/quickstart\n",
        "\n",
        "### Spark NLP Google T5 Article \t\n",
        "https://towardsdatascience.com/hands-on-googles-text-to-text-transfer-transformer-t5-with-spark-nlp-6f7db75cecff\n",
        "\n",
        "### You can find details about Spark NLP annotators here:\n",
        "https://nlp.johnsnowlabs.com/docs/en/annotators\n",
        "\n",
        "### You can find details about Spark NLP models here:\n",
        "https://nlp.johnsnowlabs.com/models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJktFHdHL1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4e3179-51d3-49a8-fae1-8eb984d06756"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-01 16:45:58--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-06-01 16:45:59--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                     0%[                    ]       0  --.-KB/s               setup Colab for PySpark 3.0.2 and Spark NLP 3.0.3\n",
            "-                   100%[===================>]   1.57K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-06-01 16:45:59 (1.90 MB/s) - written to stdout [1608/1608]\n",
            "\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [60.9 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [798 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,153 kB]\n",
            "Get:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [423 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,413 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,770 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [452 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,184 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,585 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [906 kB]\n",
            "Get:26 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [41.5 kB]\n",
            "Fetched 13.1 MB in 4s (3,009 kB/s)\n",
            "Reading package lists... Done\n",
            "\u001b[K     |████████████████████████████████| 204.8MB 76kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 69.4MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIT5VLxS3I1"
      },
      "source": [
        "## 2. Start the Spark session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khjM-z9ORFU3"
      },
      "source": [
        "Import dependencies and start Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-t1zxlHTB7"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgiqfX5XDqb"
      },
      "source": [
        "## 3. Select the DL model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPqBOgDhnvjB"
      },
      "source": [
        "For complete model list: \n",
        "https://nlp.johnsnowlabs.com/models\n",
        "\n",
        "For `T5` models:\n",
        "https://nlp.johnsnowlabs.com/models?tag=t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQACwlw5dJT6"
      },
      "source": [
        "##4. Text Summaization using T5 Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftYgju4XOw_"
      },
      "source": [
        " Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBggF5P8J1gc",
        "outputId": "0a8e0b84-87da-4682-f019-63a2bdea13fd"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"documents\")\n",
        "\n",
        "t5 = T5Transformer() \\\n",
        "  .pretrained(\"t5_small\", 'en') \\\n",
        "  .setTask(\"summarize:\")\\\n",
        "  .setMaxOutputLength(200)\\\n",
        "  .setInputCols([\"documents\"]) \\\n",
        "  .setOutputCol(\"summaries\")\n",
        "\n",
        "summarizer_pp = Pipeline(stages=[\n",
        "    document_assembler, t5\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t5_small download started this may take some time.\n",
            "Approximate size to download 139 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0abcwhXWC-"
      },
      "source": [
        "Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYf_9sXDXR4t"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = summarizer_pp.fit(empty_df)\n",
        "sum_lmodel = LightPipeline(pipeline_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEIV1vUsv8ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6844cad-1789-45fb-f696-183667ff9664"
      },
      "source": [
        "example_txt = \"\"\"\n",
        "\n",
        "I'm interested in the laws around eliminating PMI on my mortgage. \n",
        "My original mortgage was for 140,000. My property appraised out at 169,000, but I paid 155,000 (I negotiated hard!). I currently owe 126,000. \n",
        "My automatic PMI removal date was set for Feb 2024 based on just paying the minimum payment -- however, I have been paying aggressively. \n",
        "From what I understand, the bank is obligated to stop charging for PMI once I reach 78% of my homes original appraised value. I reached 78% over a year ago. I spoke to someone at USbank and they said it doesn't work that way; that the original cost of the purchase is considered and not the appraised value, and that I have to wait until 2024, pay down more (?) or have another appraisal done. Honestly, I don't totally understand what they meant.\n",
        "Does any know what the issue might be? Is it not as straightforward as the internet might have me believe? :)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "res = sum_lmodel.fullAnnotate(example_txt)[0]\n",
        "\n",
        "\n",
        "print ('Summary:', res['summaries'][0].result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary: a bank is obligated to stop charging for PMI once I reach 78% of my homes original appraised value . a bank says it doesn't work that way; the original cost of the purchase is considered and not the appraised value . a bank says it's not as straightforward as the internet might have me believe .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4IvZbhUv9YU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QPs_I1JeaFV"
      },
      "source": [
        "##5. Question Answering using T5 Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oup7_-KNefgz"
      },
      "source": [
        " Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmIBAkUWeiAO",
        "outputId": "cdf3d249-08c4-4de2-a3ad-f17f5b27d224"
      },
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"documents\")\n",
        "\n",
        "sentence_detector = SentenceDetectorDLModel\\\n",
        "    .pretrained(\"sentence_detector_dl\", \"en\")\\\n",
        "    .setInputCols([\"documents\"])\\\n",
        "    .setOutputCol(\"questions\")\n",
        "\n",
        "t5 = T5Transformer()\\\n",
        "    .pretrained(\"google_t5_small_ssm_nq\", 'en')\\\n",
        "    .setInputCols([\"questions\"])\\\n",
        "    .setOutputCol(\"answers\")\\\n",
        "\n",
        "qa_pp = Pipeline(stages=[\n",
        "    document_assembler, sentence_detector, t5\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "google_t5_small_ssm_nq download started this may take some time.\n",
            "Approximate size to download 139 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBRwmr-lfB6T"
      },
      "source": [
        "Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pry1KLQExlpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153e6948-b760-4832-f27b-4962ad161180"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = qa_pp.fit(empty_df)\n",
        "qa_lmodel = LightPipeline(pipeline_model)\n",
        "\n",
        "questions = [\"Do student loans or credit card debt take precedence?\",\n",
        "             \"How does Wageworks work?\",\n",
        "             \"What to ask for when buying a used car?\",\n",
        "             \"How fast does your credit score actually update?\",\n",
        "             \"What happens with unused credit card accounts?\"\n",
        "]\n",
        "\n",
        "res = qa_lmodel.fullAnnotate(questions)\n",
        "\n",
        "\n",
        "for i, r in enumerate(res):\n",
        "  print (\"Question:\", questions[i])\n",
        "  for sent in r['answers']:\n",
        "    print ('Answer:\\t', sent.result)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question: Do student loans or credit card debt take precedence?\n",
            "Answer:\t Over one million students\n",
            "Question: How does Wageworks work?\n",
            "Answer:\t sales of ten million units\n",
            "Question: What to ask for when buying a used car?\n",
            "Answer:\t car gage\n",
            "Question: How fast does your credit score actually update?\n",
            "Answer:\t until you are interrogated\n",
            "Question: What happens with unused credit card accounts?\n",
            "Answer:\t bankruptcy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqefWQpU0FjR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}